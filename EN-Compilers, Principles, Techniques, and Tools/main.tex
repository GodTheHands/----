\documentclass[a4paper,twoside]{book}
\usepackage{amd}

% %--------------------------------------------------------------------------
% %         General Setting
% %--------------------------------------------------------------------------

\graphicspath{{Images/}{../Images/}} %Path of figures
\setkeys{Gin}{width=0.85\textwidth} %Size of figures
\setlength{\cftbeforechapskip}{3pt} %space between items in toc
\setlength{\parindent}{0.5cm} % Idk
\input{theorems.tex} % Theorems styles and colors
\usepackage[english]{babel} %Language
\usepackage{framed}

\setlist[itemize]{itemsep=5pt} % Adjust the length as needed
\setlist[enumerate]{itemsep=5pt} % Adjust the length as needed



% \usepackage{lmodern} %  Latin Modern font
% \usepackage{newtxtext,newtxmath}




% %--------------------------------------------------------------------------
% %         General Informations
% %--------------------------------------------------------------------------
\newcommand{\BigTitle}{
    Compilers: Principles, Techniques, \& Tools
    }

\newcommand{\LittleTitle}{
    By Alfred V. Aho et all
    }

    
\begin{document}

% %--------------------------------------------------------------------------
% %         First pages 
% %--------------------------------------------------------------------------
\newgeometry{top=8cm,bottom=.5in,left=2cm,right=2cm}
\subfile{files/0.0.0.titlepage}
\restoregeometry
\thispagestyle{empty}
\setcounter{page}{0}
\tableofcontents
\thispagestyle{empty}
\setcounter{page}{0}

% %--------------------------------------------------------------------------
% %         Core of the document 
% %--------------------------------------------------------------------------
\chapter{Introduction}

The world as we know it depends on programming languages, because all the software running on all the computers was written in some programming language. But, before a program can be run, it first must be translated into a form in which it can be executed by a computer.

The software systems that do this translation are called \textit{compilers}.

\section{Language Processors}

Simply stated, a compiler is a program that can read a program in one language--the \textit{source} language--and translate it into an equivalent program in another language--the \textit{target} language.

An \textit{interpreter} is another common kind of language processor.

The task of collecting the source program is sometimes entrusted to a separate program, called a \textit{preprocessor}.

The compiler may produce an assembly-language program as its output, because assembly language is easier to produce as output and is easier to debug. The assembly language is then processed by a program called an \textit{assembler} that produces relocatable machine code as its output.

The \textit{linker} resolves external memory addresses, where the code in one file may refer to a location in another file. The \textit{loader} then puts together all of the executable object files into memory for execution.

\section{The Structure of a Compiler}

Up to this point we have treated a compiler as a single box that maps a source program into a semantically equivalent target program. If we open up this box a little, we see that there are two parts to this mapping: analysis and synthesis.

The \textit{analysis} part breaks up the source program into constituent pieces and imposes a grammatical structure on them. The analysis part also collects information about the source program and stores it in a data structure called a \textit{symbol table}, which is passed along with the intermediate representation to the synthesis part.

The \textit{synthesis} part constructs the desired target program from the intermediate representation and the information in the symbol table. The analysis part is often called the \textit{front end} of the compiler; the synthesis part is the \textit{back end}.

If we examine the compilation process in more detail, we see that it operates as a sequence of \textit{phases}, each of which transforms one representation of the source program to another.

\subsection{Lexical Analysis}

The first phase of a compiler is called \textit{lexical analysis} or \textit{scanning}. The lexical analyzer reads the stream of characters making up the source program and groups the characters into meaningful sequences called \textit{lexemes}. For each lexeme, the lexical analyzer produces as output a \textit{token} of the form $$\langle\textit{token-name, attribute-value}\rangle$$ that is passes on to the subsequent phase, syntax analysis. In the token, the first component \textit{token-name} is an abstract symbol that is used during syntax analysis, and the second component \textit{attribute-value} points to an entry in the symbol table for this token.

\subsection{Syntax Analysis}

The second phase of the compiler is \textit{syntax analysis} or \textit{parsing}. A typical representation is a \textit{syntax tree} in which each interior node represents an operation and the children of the node represent the arguments of the operation.

\subsection{Semantic Analysis}

The \textit{semantic analyzer} uses the syntax tree and the information in the symbol table to check the source program for semantic consistency with the language definition.

An important part of semantic analysis is \textit{type checking}, where the compiler checks that each operator has matching operands.

The language specification may permit some type conversions called \textit{coercions}.

\subsection{Intermediate Code Generation}

We consider an intermediate form called \textit{three-address code}, which consists of a sequence of assembly-like instructions with three operands per instruction.

\subsection{The Grouping of Phases into Passes}

In an implementation, activities from several phases may be grouped together into a \textit{pass} that reads an input file and writes an output file.

\subsection{Compiler-Construction Tools}

Some commonly used compiler-construction tools include
\begin{enumerate}
    \item \textit{Parser generators} that automatically produce syntax analyzers from a grammatical description of a programming language.
    \item \textit{Scanner generators} that produce lexical analyzers from a regular-expression description of the tokens of a language.
    \item \textit{Syntax-directed translation engines} that produce collections of routines for walking a parse tree and generating intermediate code.
    \item \textit{Code-generator generators} that produce a code generator from a collection of rules for translating each operation of the intermediate language into the machine language for a target machine.
    \item \textit{Data-flow analysis engines} that facilitate the gathering of information about how values are transmitted from one part of a program to each other part.
    \item \textit{Compiler-construction toolkits} that provide an integrated set of routines for construction various phases of a compiler.
\end{enumerate}

\section{The Evolution of Programming Language}
\subsection{The Move to Higher-Level Languages}

One classification is by generation. \textit{First-generation languages} are the machine languages, \textit{second-generation} the assembly languages, and \textit{third-generation} the higher-level languages. \textit{Fourth-generation languages} are languages designed for specific applications. The term \textit{fifth-generation language} has been applied to logic- and constraint-based languages.

Another classification of languages uses the term \textit{imperative} for languages in which a program specifies \textit{how} a computation is to be done and \textit{declarative} for languages in which a program specifies \textit{what} computation is to be done.

The term \textit{von Neumann language} is applied to programming languages whose computational model is based on the von Neumann computer architecture.

An \textit{object-oriented language} is one that supports object-oriented programming, a programming style in which a program consists of a collection of objects that interact with one another.

\textit{Scripting languages} are interpreted languages with high-level operators designed for "gluing together" computations.

\section{Applications of Compiler Technology}
\subsection{implementation of High-Level Programming Languages}

A body of compiler optimizations, known as \textit{data-flow optimizations}, has been developed to analyze the flow of data through the program and removes redundancies across these constructs.

Object-oriented programs are different from those written in many other languages, in that they consist of many more, but smaller, procedures (called \textit{methods} in object-oriented terms).

\subsection{Optimizations for Computer Architectures}

Almost all high-performance systems take advantage of the same two basic techniques: \textit{parallelism} and \textit{memory hierarchies}. Parallelism can be found at several levels: at the \textit{instruction level}, where multiple operations are executed simultaneously and at the \textit{processor level}, where different threads of the same application are run on different processors.

\section{Programming Language Basics}
\subsection{The Static/Dynamic Distinction}

If a language uses a policy that allows the compiler to decide an issue, then we say that the language uses a \textit{static} policy or that the issue can be decided at \textit{compile time}. On the other hand, a policy that only allows a decision to be made when we execute the program is said to be a \textit{dynamic policy} or to require a decision at \textit{run time}.

The \textit{scope} of a declaration of $x$ is the region of the program in which uses of $x$ refer to this declaration. A language uses \textit{static scope} or \textit{lexical scope} if it is possible to determine the scope of a declaration by looking only at the program. Otherwise, the language uses \textit{dynamic scope}.

\subsection{Environments and States}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{Figure1 8.pdf}
    \caption{Two-stage mapping from names to values}
    \label{figure:1.8}
\end{figure}

The association of names with locations in memory (the \textit{store}) and then with values can be described by two mappings that change as the program runs:
\begin{enumerate}
    \item The \textit{environment} is a mapping from names to locations in the store.
    \item The \textit{state} is a mapping from locations in store to their values.
\end{enumerate}

The environment and state mappings in Fig.\;\ref{figure:1.8} are dynamic, but there are a few exceptions:
\begin{enumerate}
    \item \textit{Static versus dynamic binding} of names to locations.
    \item \textit{Static versus dynamic binding} of locations to values.
\end{enumerate}

\begin{framed}
\begin{center}
    \textbf{{\large Names, Identifiers, and Variables}}
\end{center}

An \textit{identifier} is a string of characters, typically letters or digits, that refers to (identifies) an entity. Composite names are called \textit{qualified} names.

A \textit{variable} refers to a particular location of the store.
\end{framed}

\subsection{Static Scope and Block Structure}

The scope rules for C are based on program structure; the scope of a declaration is determined implicitly by where the declaration appears in the program. Later languages also provide explicit control over scopes through the use of keywords like \textbf{public}, \textbf{private} and \textbf{protected}.

A \textit{block} is a grouping of declarations and statements. C uses braces \texttt{\{} and \texttt{\}} to delimit a block; the alternative use of \textbf{begin} and \textbf{end} for the same purpose dates back to Algol.

In C, the syntax of blocks is given by
\begin{enumerate}
    \item One type of statement is a block. Blocks can appear anywhere that other types of statement can appear.
    \item A block is a sequence of declarations followed by a sequence of statements, all surrounded by braces.
\end{enumerate}

Note that this syntax allows blocks to be nested inside each other. This nesting property is referred to as \textit{block structure}.

\subsection{Explicit Access Control}

Through the use of keywords like \textbf{public}, \textbf{private}, and \textbf{protected}, object-oriented languages provide explicit control over access to member names in a superclass. These keywords support \textit{encapsulation} by restricting access.

\subsection{Dynamic Scope}

Technically, any scoping policy is dynamic if it is based on factor(s) that can be known only when the program executes. The term \textit{dynamic scope}, however, usually refers to the following policy: a use of a name $x$ refers to the declaration of $x$ in the most recently called procedure with such a declaration.

\begin{framed}
    \begin{center}
        \textbf{{\large Declarations and Definitions}}
    \end{center}

    In C++, a method is declared in a class definition, by giving the types of the arguments and result of the method (often called the \textit{signature} for the method).
\end{framed}

\subsection{Parameter Passing Mechanisms}

\textit{Actual parameters} (the parameters used in the call of a procedure) are associated with the \textit{formal parameters} (those used in the procedure definition).

\subsubsection{Call-by-Value}

In \textit{call-by-value}, the actual parameter is evaluated (if it is an expression) or copied (if it is a variable).

\subsubsection{Call-by-Reference}

In \textit{call-by-reference}, the address of the actual parameter is passed to the callee as the value of the corresponding formal parameter.

\subsection{Aliasing}

It is possible that two formal parameters can refer to the same location; such variables are said to be \textit{aliases} of one another.

\chapter{A Simple Syntax-Directed Translator}
\section{Introduction} 

The \textit{syntax} of a programming language defines what its programs, while the \textit{semantics} of the language defines what its program mean; that is, what each program does when it executes.

A lexical analyzer allows a translator to handle mutlicharacter constructs like identifiers, which are written as sequences of charactersm, but are treated as units called \textit{tokens} during syntax analysis.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{Figure2 4.pdf}
    \caption{Intermediate code for "\texttt{do i=i+1; while(a[i]<v);}"}
    \label{figure:2.4}
\end{figure}

Two forms of intermediate code are illustrated in Fig.\;\ref{figure:2.4}. One form, called \textit{abstract syntax trees} or simply \textit{syntax trees}, represents the hierarchical systematic structure of the source program.

\section{Syntax Definition}

A grammar naturally describes the hierarchical structure of most programming language constructs. For example, an if-else statement in Java can have the form
\begin{center}
    \textbf{if} (expression) statement \textbf{else} statement
\end{center}

Using the variable \textit{expr} to denote an expression and the variable \textit{stmt} to denote a statement, this structuring rule can be expressed as
\begin{center}
    \textit{stmt} $\rightarrow$ \textbf{if} (\textit{expr}) \textit{stmt} \textbf{else} \textit{stmt}
\end{center}
in which the arrow may be read as "can have the form." Such a rule is called a \textit{production}. In a production, lexical elements are called \textit{terminals}. Variables like \textit{expr} and \textit{stmt} represent sequences of terminals and are called \textit{nonterminals}.

\subsection{Definition of Grammars}

A \textit{context-free grammar} has four components:
\begin{enumerate}
    \item A set of \textit{terminal} symbols, sometimes referred to as "tokens."
    \item A set of \textit{nonterminals}, sometimes called "syntactic variables."
    \item A set of \textit{productions}, where each production consists of a nonterminal, called the \textit{head} or \textit{left side} of the production, an arrow, and a sequence of terminals and/or nonterminals, called the \textit{body} or \textit{right side} of the production.
    \item A designation of one of the nonterminals as the \textit{start} symbol.
\end{enumerate}

\begin{framed}
    \begin{center}
        \textbf{{\large Tokens Versus Terminals}}
    \end{center}

    A token consists of two components, a token name and an attribute value. The token names are abstract symbols that are used by the parser for syntax analysis. Often, we shall call these token names \textit{terminals}, since they appear as terminal symbols in the grammar for a programming language.
\end{framed}

We say a production is \textit{for} a nonterminal if the nonterminal is the head of the production. The string of zero terminals, written as $\epsilon$, is called the \textit{empty} string.

\subsection{Derivations}

The terminal strings that can be derived from the start symbol form the \textit{language} defined by the grammar.

\textit{Parsing} is the problem of taking a string of terminals and figuring out how to derive it from the start symbol of the grammar, and if it cannot be derived from the start symbol of the grammar, then reporting syntax errors within the string.

\subsection{Parse Trees}

A parse tree pictorially shows how the start symbol of a grammar derives a string in the language.

Formally, given a context-free grammar, a \textit{parse tree} according to the grammar is a tree with the following properties:
\begin{enumerate}
    \item The root is labeled by the start symbol.
    \item Each leaf is labeled by a terminal or by $\epsilon$.
    \item Each interior node is labeled by a nonterminal.
    \item If $A$ is the nonterminal labeling some interior node and $X_1,X_2,\cdots,X_n$ are the labels of the children of that node from left to right, then there must be a production $A\rightarrow X_1X_2\cdots X_n$.
\end{enumerate}

\begin{framed}
    \begin{center}
        \textbf{{\large Tree Terminology}}
    \end{center}

    Tree data structures figure prominently in compiling.
    \begin{itemize}
        \item A tree consists of one or more \textit{nodes}. Nodes may have \textit{labels}.
        \item Exactly one node is the \textit{root}. All nodes except the root have a unique \textit{parent}; the root has no parent.
        \item If node $N$ is the parent of node $M$, then $M$ is a \textit{child} of $N$. The children of one node are called \textit{siblings}. They have an order, \textit{from the left}, and when we draw trees, we order the children 
        \item A node with no children is called a \textit{leaf}. Other nodes -- those with one or more children -- are \textit{interior nodes}.
        \item A \textit{descendant} of a node $N$ is either $N$ itself, a child of $N$, a child of a child of $N$, and so on, for any number of levels. We say node $N$ is an \textit{ancestor} of node $M$ if $M$ is a descendant of $N$.
    \end{itemize}
\end{framed}

From left to right, the leaves of a parse tree form the \textit{yield} of the tree, which is the string \textit{generated} or \textit{derived} from the nonterminal at the root of the parse tree.

The process of finding a parse tree for a given string of terminals is called \textit{parsing} that string.

\subsection{Ambiguity}

We have to be careful in talking about \textit{the} structure of a string according to a grammar. A grammar can have more than one parse tree generating a given string of terminals. Such a grammar is said to be \textit{ambiguous}.

\subsection{Associativity of Operators}

We say that the operator $+$ \textit{associates} to the left, because an operand with plus signs on both sides of it belongs to the operator to its left.

\subsection{Precedence of Operators}

We say that $*$ has \textit{higher precedence} than $+$ if $*$ takes its operands before $+$ does.

\section{Syntax-Directed Translation}

% %--------------------------------------------------------------------------
% %         Bibliographie 
% %--------------------------------------------------------------------------
\end{document}
